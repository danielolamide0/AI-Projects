{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxUtCYYbokAj",
        "outputId": "5ee2dae5-3ade-423d-faa8-37a451404fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhBzH-qLrVkK"
      },
      "outputs": [],
      "source": [
        "!unzip -n -q \"/content/drive/MyDrive/archive.zip\" -d \"/content/drive/MyDrive/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications import EfficientNetB3, ResNet50, InceptionV3\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Data Loading\n",
        "\n",
        "# Define directories\n",
        "train_dir = '/content/drive/MyDrive/Data/train'\n",
        "valid_dir = '/content/drive/MyDrive/Data/valid'\n",
        "test_dir = '/content/drive/MyDrive/Data/test'\n",
        "\n",
        "# Function to create data frames from image paths and labels\n",
        "def create_dataframe(directory):\n",
        "    labels = os.listdir(directory)\n",
        "    file_paths = []\n",
        "    categories = []\n",
        "    for label in labels:\n",
        "        label_dir = os.path.join(directory, label)\n",
        "        for file in os.listdir(label_dir):\n",
        "            file_paths.append(os.path.join(label_dir, file))\n",
        "            categories.append(label)\n",
        "    df = pd.DataFrame({'File_Path': file_paths, 'Category': categories})\n",
        "    return df\n",
        "\n",
        "# Create data frames for training, validation, and testing\n",
        "train_df = create_dataframe(train_dir)\n",
        "valid_df = create_dataframe(valid_dir)\n",
        "test_df = create_dataframe(test_dir)\n",
        "\n",
        "# Step 2: Image Data Generators\n",
        "\n",
        "# Define parameters\n",
        "image_size = (300, 300)\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation for training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# No augmentation for validation and test sets\n",
        "valid_test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "# Create data generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='File_Path',\n",
        "    y_col='Category',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_test_datagen.flow_from_dataframe(\n",
        "    valid_df,\n",
        "    x_col='File_Path',\n",
        "    y_col='Category',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = valid_test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='File_Path',\n",
        "    y_col='Category',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Step 3: Model Training (EfficientNetB3, ResNet50, InceptionV3)\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (*image_size, 3)\n",
        "\n",
        "# Load pre-trained models without top layer\n",
        "base_model_efficientnet = EfficientNetB3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "base_model_inception = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Add custom classification layers\n",
        "x = GlobalAveragePooling2D()(base_model_efficientnet.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions_efficientnet = Dense(len(train_df['Category'].unique()), activation='softmax')(x)\n",
        "model_efficientnet = Model(inputs=base_model_efficientnet.input, outputs=predictions_efficientnet)\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model_resnet50.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions_resnet50 = Dense(len(train_df['Category'].unique()), activation='softmax')(x)\n",
        "model_resnet50 = Model(inputs=base_model_resnet50.input, outputs=predictions_resnet50)\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model_inception.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions_inception = Dense(len(train_df['Category'].unique()), activation='softmax')(x)\n",
        "model_inception = Model(inputs=base_model_inception.input, outputs=predictions_inception)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRh8g5ZZmOrn",
        "outputId": "c88e1277-d22d-4a46-c749-ffb79ce7aa7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 613 validated image filenames belonging to 4 classes.\n",
            "Found 72 validated image filenames belonging to 4 classes.\n",
            "Found 315 validated image filenames belonging to 4 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "43941136/43941136 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile models\n",
        "models = [model_efficientnet, model_resnet50, model_inception]\n",
        "for model in models:\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train models\n",
        "for model in models:\n",
        "    checkpoint = ModelCheckpoint(filepath=model.name+'_best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        epochs=10,\n",
        "        validation_data=valid_generator,\n",
        "        callbacks=[checkpoint]\n",
        "    )\n",
        "\n",
        "# Load best versions of models\n",
        "best_models = [Model(inputs=model.input, outputs=model.output) for model in models]\n",
        "for i, model in enumerate(best_models):\n",
        "    model.load_weights(models[i].name+'_best_model.h5')\n",
        "\n",
        "# Create ensemble model\n",
        "ensemble_inputs = [model.input for model in best_models]\n",
        "ensemble_outputs = [model.output for model in best_models]\n",
        "ensemble_output = Dense(len(train_df['Category'].unique()), activation='softmax')(concatenate(ensemble_outputs))\n",
        "ensemble_model = Model(inputs=ensemble_inputs, outputs=ensemble_output)\n",
        "\n",
        "# Compile ensemble model\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xSpkfovmZmU",
        "outputId": "2e03d5ea-69c5-4022-edb4-4c4a396aa29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.8536 - accuracy: 0.6297"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 198s 6s/step - loss: 0.8536 - accuracy: 0.6297 - val_loss: 1.7253 - val_accuracy: 0.2083\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 19s 931ms/step - loss: 0.4617 - accuracy: 0.8157 - val_loss: 3.7307 - val_accuracy: 0.2083\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 19s 958ms/step - loss: 0.2368 - accuracy: 0.9038 - val_loss: 3.0649 - val_accuracy: 0.2083\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.3401 - accuracy: 0.8940 - val_loss: 2.3374 - val_accuracy: 0.2917\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 20s 982ms/step - loss: 0.2419 - accuracy: 0.9135 - val_loss: 16.5372 - val_accuracy: 0.1806\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.2985 - accuracy: 0.9168 - val_loss: 4.7861 - val_accuracy: 0.1806\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 19s 945ms/step - loss: 0.2708 - accuracy: 0.9184 - val_loss: 9.8545 - val_accuracy: 0.1806\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 19s 949ms/step - loss: 0.2630 - accuracy: 0.9201 - val_loss: 8.9843 - val_accuracy: 0.1806\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 20s 961ms/step - loss: 0.0989 - accuracy: 0.9674 - val_loss: 5.9298 - val_accuracy: 0.1806\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 20s 981ms/step - loss: 0.1163 - accuracy: 0.9625 - val_loss: 9.9997 - val_accuracy: 0.1806\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 66s 1s/step - loss: 1.3858 - accuracy: 0.4894 - val_loss: 2029535.1250 - val_accuracy: 0.1806\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 14s 659ms/step - loss: 0.9507 - accuracy: 0.5563 - val_loss: 40465264.0000 - val_accuracy: 0.1806\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 15s 748ms/step - loss: 1.0152 - accuracy: 0.5139 - val_loss: 2.1501 - val_accuracy: 0.3194\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 14s 674ms/step - loss: 1.0307 - accuracy: 0.5808 - val_loss: 8.5976 - val_accuracy: 0.3194\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 13s 657ms/step - loss: 0.9847 - accuracy: 0.5498 - val_loss: 1465.3732 - val_accuracy: 0.3194\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 13s 654ms/step - loss: 0.9535 - accuracy: 0.5302 - val_loss: 4.9741 - val_accuracy: 0.3194\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 13s 655ms/step - loss: 0.8980 - accuracy: 0.5465 - val_loss: 6.7879 - val_accuracy: 0.1806\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 13s 655ms/step - loss: 0.8321 - accuracy: 0.6052 - val_loss: 2.5467 - val_accuracy: 0.3194\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 13s 654ms/step - loss: 0.7471 - accuracy: 0.6150 - val_loss: 1.3902 - val_accuracy: 0.2917\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 13s 653ms/step - loss: 0.8288 - accuracy: 0.5938 - val_loss: 1.3742 - val_accuracy: 0.2917\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 71s 1s/step - loss: 1.2831 - accuracy: 0.5204 - val_loss: 309.1222 - val_accuracy: 0.1806\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 10s 483ms/step - loss: 0.8131 - accuracy: 0.6672 - val_loss: 924.8259 - val_accuracy: 0.1806\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 10s 510ms/step - loss: 0.6161 - accuracy: 0.7830 - val_loss: 185018.6094 - val_accuracy: 0.1806\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 10s 496ms/step - loss: 0.5506 - accuracy: 0.7961 - val_loss: 29297.9785 - val_accuracy: 0.1806\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 12s 567ms/step - loss: 0.5170 - accuracy: 0.8303 - val_loss: 261870.1406 - val_accuracy: 0.2917\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 10s 533ms/step - loss: 0.6132 - accuracy: 0.7912 - val_loss: 144.5530 - val_accuracy: 0.2917\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 11s 562ms/step - loss: 0.4471 - accuracy: 0.8385 - val_loss: 4218.6240 - val_accuracy: 0.3194\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 11s 516ms/step - loss: 0.4048 - accuracy: 0.8777 - val_loss: 218.7082 - val_accuracy: 0.1806\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 11s 519ms/step - loss: 0.2124 - accuracy: 0.9364 - val_loss: 47.9743 - val_accuracy: 0.2778\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 12s 580ms/step - loss: 0.2291 - accuracy: 0.9103 - val_loss: 8.7627 - val_accuracy: 0.4167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for the test data using the ensemble model\n",
        "test_generator.reset()  # Reset generator to start from the beginning\n",
        "y_pred_list = []\n",
        "for i in range(len(test_generator)):\n",
        "    batch_images, _ = test_generator[i]\n",
        "    y_pred_batch = ensemble_model.predict([batch_images] * len(best_models))\n",
        "    y_pred_list.append(y_pred_batch)\n",
        "\n",
        "# Concatenate predictions from all batches\n",
        "y_pred = np.concatenate(y_pred_list)\n",
        "\n",
        "# Get true labels from the test generator\n",
        "y_true = []\n",
        "for i in range(len(test_generator)):\n",
        "    _, labels = test_generator[i]\n",
        "    y_true.extend(np.argmax(labels, axis=1))\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Compute classification report\n",
        "report = classification_report(y_true, y_pred_labels)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k57U5g0mphmd",
        "outputId": "e8b47965-8ade-4665-bc2a-cf7a788f0962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 0s 414ms/step\n",
            "1/1 [==============================] - 0s 415ms/step\n",
            "1/1 [==============================] - 0s 328ms/step\n",
            "1/1 [==============================] - 0s 370ms/step\n",
            "1/1 [==============================] - 0s 382ms/step\n",
            "1/1 [==============================] - 0s 315ms/step\n",
            "1/1 [==============================] - 0s 349ms/step\n",
            "1/1 [==============================] - 0s 378ms/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.60      0.55       120\n",
            "           1       0.00      0.00      0.00        51\n",
            "           2       0.00      0.00      0.00        54\n",
            "           3       0.23      0.43      0.30        90\n",
            "\n",
            "    accuracy                           0.35       315\n",
            "   macro avg       0.18      0.26      0.21       315\n",
            "weighted avg       0.26      0.35      0.29       315\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}